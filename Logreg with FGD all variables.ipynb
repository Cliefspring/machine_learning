{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000, 20), (1000,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = make_classification(n_samples=1000, n_features=20, n_classes=2)\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = np.hstack([np.ones((1000, 1)), X]) # to add intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.03060796,  0.01948247,  0.01855188,  0.03244342,  0.03462413,\n",
       "         0.03193399, -0.02155626,  0.01240107,  0.04735593, -0.00730769,\n",
       "         0.01367596,  0.01885292,  0.03472163, -0.00434747, -0.03232739,\n",
       "        -0.01466931,  0.02706135,  0.00597234,  0.01005371, -0.00861443]),\n",
       " array([0.96509178, 1.01583209, 0.97798208, 0.9966703 , 1.01065482,\n",
       "        0.98071258, 0.96732736, 1.04320882, 1.04007165, 0.97859211,\n",
       "        1.12901516, 1.01655085, 1.00878989, 0.98378539, 1.02168685,\n",
       "        1.3216333 , 1.01699317, 1.29599272, 0.90793208, 0.98017205]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.mean(axis=0), X.std(axis=0) # no need to standardize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My Logistic Regression Class realization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features to add:\n",
    "- <b>Different types of gradient descent (GD) </b>\n",
    "    - Full GD (already implemented)\n",
    "    - stochastic GD (SGD) one random object used to find gradient\n",
    "    - stochastic average SAGD (several random objects used to find gradient)\n",
    "    \n",
    "- <b>Different loss functions </b>\n",
    "    - Logloss (already implemented)\n",
    "    - MSE :) for fun\n",
    "- <b>Info about model </b>\n",
    "    - Coefficients, intercept, parameters set (learning rate, regularization)\n",
    "    - Stats (p-values, confidence intervals, model adequacy)\n",
    "    - Quality metrics w\n",
    "- <b> Marginal Effects (ME) </b>\n",
    "        - ME for each factor\n",
    "        - ME at means, median, at any factors given\n",
    "        - average ME (AME) for each factor\n",
    "- <b> Non-linear factors </b>\n",
    "        - ME for them also"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Logreg:\n",
    "    def __init__(self, learning_rate=0.05, iterations=1500, C=1.0):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.iterations = iterations\n",
    "        self.C = C\n",
    "        self.weights = None\n",
    "        self.intercept = None\n",
    "        \n",
    "        # history\n",
    "        self.iters_list = []\n",
    "        self.loss_list = []\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        # number of observations\n",
    "        n = len(y)\n",
    "        # number of features\n",
    "        k = X.shape[1]\n",
    "        \n",
    "        # 1. Initialize weights\n",
    "        self.weights = np.zeros(k)\n",
    "        self.intercept = 0\n",
    "        \n",
    "        for iteration in range(self.iterations):\n",
    "            # 2 Predict\n",
    "            z = np.dot(X, self.weights) + self.intercept\n",
    "            y_hat = 1 / (1 + np.exp(-z))\n",
    "            # 3 Calculate logloss\n",
    "            #logloss = np.sum(-y * np.log(y_hat) - (1 - y) * np.log(1 - y_hat))\n",
    "            logloss = np.sum(np.log(1 + np.exp(- y * y_hat)))\n",
    "        \n",
    "            # 4 Derivative by weights\n",
    "            derivative_weights = (1 / n) * np.dot(X.T, (y_hat - y)) # (a - y) * x\n",
    "            derivative_intercept = (1 / n) * np.sum(y_hat - y)\n",
    "\n",
    "            # 5 Update weights\n",
    "            self.weights -= self.learning_rate * (derivative_weights + self.C * self.weights)\n",
    "            self.intercept -= self.learning_rate * (derivative_intercept + self.C * self.intercept)\n",
    "            \n",
    "            #print('Iteration:', iteration, 'Total logLoss =', logloss)\n",
    "            \n",
    "            # history update\n",
    "            self.iters_list.append(iteration)\n",
    "            self.loss_list.append(logloss)\n",
    "            # 6 Repeat\n",
    "    \n",
    "\n",
    "    def predict(self, X):\n",
    "        z = np.dot(X, self.weights) + self.intercept\n",
    "        pred = 1 / (1 + np.exp(-z))\n",
    "        return np.array([1 if i > 0.5 else 0 for i in pred])\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        z = np.dot(X, self.weights) + self.intercept\n",
    "        return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate, Fit and Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = Logreg(C=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mine_pred = logreg.predict(X)\n",
    "np.unique(mine_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(C=1.0, solver='liblinear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.55667614])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.0051079 ,  0.18580036, -0.03000362,  0.10656345,  0.14646711,\n",
       "        -0.12939623, -0.11166564,  0.12635051,  0.1195064 , -0.03171033,\n",
       "         0.81794541, -0.03529246,  0.1252057 , -0.07348786, -0.09444035,\n",
       "         0.31862608,  0.22912314,  2.92178327, -0.22983122,  0.08791236]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = lr.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000,), (1000,))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape, pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([0, 1]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y), np.unique(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison: Mine VS Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.908, 0.9080156320625283)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y, pred), roc_auc_score(y, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.89, 0.890063560254241)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y, mine_pred), roc_auc_score(y, mine_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.01549807,  0.01859498,  0.00502167,  0.00140718,  0.02130198,\n",
       "       -0.00631488, -0.01062253, -0.01900558,  0.00876403,  0.00103525,\n",
       "        0.11285081, -0.00194511,  0.02070505, -0.01657789, -0.0211903 ,\n",
       "        0.01629537,  0.01019341,  0.34379146, -0.01248403,  0.00437411])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Marginal Effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for any linear factor it is just its weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.015498069345919387"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.weights[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
